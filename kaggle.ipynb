{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2444495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e54dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "X = df.drop(columns=[\"id\",\"y\"])\n",
    "y = df[\"y\"]\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "XTEST = test_df.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8a0e192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 18 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   id         750000 non-null  int64 \n",
      " 1   age        750000 non-null  int64 \n",
      " 2   job        750000 non-null  object\n",
      " 3   marital    750000 non-null  object\n",
      " 4   education  750000 non-null  object\n",
      " 5   default    750000 non-null  object\n",
      " 6   balance    750000 non-null  int64 \n",
      " 7   housing    750000 non-null  object\n",
      " 8   loan       750000 non-null  object\n",
      " 9   contact    750000 non-null  object\n",
      " 10  day        750000 non-null  int64 \n",
      " 11  month      750000 non-null  object\n",
      " 12  duration   750000 non-null  int64 \n",
      " 13  campaign   750000 non-null  int64 \n",
      " 14  pdays      750000 non-null  int64 \n",
      " 15  previous   750000 non-null  int64 \n",
      " 16  poutcome   750000 non-null  object\n",
      " 17  y          750000 non-null  int64 \n",
      "dtypes: int64(9), object(9)\n",
      "memory usage: 103.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60fc83c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "balance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "duration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "campaign",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pdays",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "previous",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0bf963f1-5ed5-4eb1-b357-fb7f44688578",
       "rows": [
        [
         "count",
         "750000.0",
         "750000.0",
         "750000.0",
         "750000.0",
         "750000.0",
         "750000.0",
         "750000.0",
         "750000.0",
         "750000.0"
        ],
        [
         "mean",
         "374999.5",
         "40.92639466666667",
         "1204.0673973333332",
         "16.117209333333335",
         "256.229144",
         "2.577008",
         "22.412733333333332",
         "0.29854533333333333",
         "0.12065066666666667"
        ],
        [
         "std",
         "216506.49528362884",
         "10.098828887715879",
         "2836.096758725044",
         "8.250832326124739",
         "272.5556619172416",
         "2.7185137400839587",
         "77.3199981443247",
         "1.3359260446881347",
         "0.32572108430146474"
        ],
        [
         "min",
         "0.0",
         "18.0",
         "-8019.0",
         "1.0",
         "1.0",
         "1.0",
         "-1.0",
         "0.0",
         "0.0"
        ],
        [
         "25%",
         "187499.75",
         "33.0",
         "0.0",
         "9.0",
         "91.0",
         "1.0",
         "-1.0",
         "0.0",
         "0.0"
        ],
        [
         "50%",
         "374999.5",
         "39.0",
         "634.0",
         "17.0",
         "133.0",
         "2.0",
         "-1.0",
         "0.0",
         "0.0"
        ],
        [
         "75%",
         "562499.25",
         "48.0",
         "1390.0",
         "21.0",
         "361.0",
         "3.0",
         "-1.0",
         "0.0",
         "0.0"
        ],
        [
         "max",
         "749999.0",
         "95.0",
         "99717.0",
         "31.0",
         "4918.0",
         "63.0",
         "871.0",
         "200.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>750000.000000</td>\n",
       "      <td>750000.000000</td>\n",
       "      <td>750000.000000</td>\n",
       "      <td>750000.000000</td>\n",
       "      <td>750000.000000</td>\n",
       "      <td>750000.000000</td>\n",
       "      <td>750000.000000</td>\n",
       "      <td>750000.000000</td>\n",
       "      <td>750000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>374999.500000</td>\n",
       "      <td>40.926395</td>\n",
       "      <td>1204.067397</td>\n",
       "      <td>16.117209</td>\n",
       "      <td>256.229144</td>\n",
       "      <td>2.577008</td>\n",
       "      <td>22.412733</td>\n",
       "      <td>0.298545</td>\n",
       "      <td>0.120651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>216506.495284</td>\n",
       "      <td>10.098829</td>\n",
       "      <td>2836.096759</td>\n",
       "      <td>8.250832</td>\n",
       "      <td>272.555662</td>\n",
       "      <td>2.718514</td>\n",
       "      <td>77.319998</td>\n",
       "      <td>1.335926</td>\n",
       "      <td>0.325721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>187499.750000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>374999.500000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>634.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>562499.250000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1390.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>749999.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>99717.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            age        balance            day  \\\n",
       "count  750000.000000  750000.000000  750000.000000  750000.000000   \n",
       "mean   374999.500000      40.926395    1204.067397      16.117209   \n",
       "std    216506.495284      10.098829    2836.096759       8.250832   \n",
       "min         0.000000      18.000000   -8019.000000       1.000000   \n",
       "25%    187499.750000      33.000000       0.000000       9.000000   \n",
       "50%    374999.500000      39.000000     634.000000      17.000000   \n",
       "75%    562499.250000      48.000000    1390.000000      21.000000   \n",
       "max    749999.000000      95.000000   99717.000000      31.000000   \n",
       "\n",
       "            duration       campaign          pdays       previous  \\\n",
       "count  750000.000000  750000.000000  750000.000000  750000.000000   \n",
       "mean      256.229144       2.577008      22.412733       0.298545   \n",
       "std       272.555662       2.718514      77.319998       1.335926   \n",
       "min         1.000000       1.000000      -1.000000       0.000000   \n",
       "25%        91.000000       1.000000      -1.000000       0.000000   \n",
       "50%       133.000000       2.000000      -1.000000       0.000000   \n",
       "75%       361.000000       3.000000      -1.000000       0.000000   \n",
       "max      4918.000000      63.000000     871.000000     200.000000   \n",
       "\n",
       "                   y  \n",
       "count  750000.000000  \n",
       "mean        0.120651  \n",
       "std         0.325721  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07b576cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b06a1ce0-073b-41a3-8e11-12aae8848cc1",
       "rows": [
        [
         "job",
         "12"
        ],
        [
         "marital",
         "3"
        ],
        [
         "education",
         "4"
        ],
        [
         "default",
         "2"
        ],
        [
         "housing",
         "2"
        ],
        [
         "loan",
         "2"
        ],
        [
         "contact",
         "3"
        ],
        [
         "month",
         "12"
        ],
        [
         "poutcome",
         "4"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "job          12\n",
       "marital       3\n",
       "education     4\n",
       "default       2\n",
       "housing       2\n",
       "loan          2\n",
       "contact       3\n",
       "month        12\n",
       "poutcome      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(\"object\").nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86366627",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X.select_dtypes(\"number\").columns.tolist()\n",
    "cat_cols = X.select_dtypes(\"object\").columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43baa023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    def forward(self, inputs, targets):\n",
    "        eps = 1e-8\n",
    "        inputs = inputs.clamp(min=eps, max=1. - eps) \n",
    "        \n",
    "        BCE = - (targets * torch.log(inputs) + (1 - targets) * torch.log(1 - inputs))\n",
    "        pt = torch.where(targets==1, inputs, 1 - inputs)\n",
    "        focal = self.alpha * (1-pt)**self.gamma*BCE\n",
    "        return focal.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5d67ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim,256); self.drop1=nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(256,128); self.drop2=nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(256+128,64); self.drop3=nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(64,1)\n",
    "    def forward(self,x):\n",
    "        x1 = F.relu(self.fc1(x)); x1=self.drop1(x1)\n",
    "        x2 = F.relu(self.fc2(x1)); x2=self.drop2(x2)\n",
    "        x_cat = torch.cat([x2,x1],1)\n",
    "        x3 = F.relu(self.fc3(x_cat)); x3=self.drop3(x3)\n",
    "        return torch.sigmoid(self.out(x3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ebacb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ffnn_oof(X_tr, y_tr, X_va):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = FFNN(X_tr.shape[1]).to(device)\n",
    "    opt   = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    crit  = FocalLoss() \n",
    "    ds = TensorDataset(\n",
    "        torch.tensor(X_tr, dtype=torch.float32),\n",
    "        torch.tensor(np.asarray(y_tr), dtype=torch.float32).unsqueeze(1)\n",
    "    )\n",
    "    dl = DataLoader(ds, batch_size=768, shuffle=True)\n",
    "    model.train()\n",
    "    for _ in range(10):\n",
    "        for xb,yb in dl:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(xb), yb)\n",
    "            loss.backward(); opt.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(torch.tensor(\n",
    "            X_va, dtype=torch.float32).to(device)\n",
    "        ).squeeze().cpu().numpy()\n",
    "    return preds, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46e63a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    "    \n",
    ")\n",
    "prep_nn = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\", StandardScaler())   \n",
    "        ]),num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06afa492",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_ffnn = np.zeros(len(X), dtype=np.float32)\n",
    "oof_lgb  = np.zeros(len(X), dtype=np.float32)\n",
    "oof_cat  = np.zeros(len(X), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9ef17ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 72391, number of negative: 527609\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1046\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 51\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (6.87 MB) transferred to GPU in 0.005423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120652 -> initscore=-1.986273\n",
      "[LightGBM] [Info] Start training from score -1.986273\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1516]\tvalid_0's auc: 0.970082\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 5395.6875 Total: 7797.125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 72391, number of negative: 527609\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1044\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 51\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (6.87 MB) transferred to GPU in 0.005142 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120652 -> initscore=-1.986273\n",
      "[LightGBM] [Info] Start training from score -1.986273\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1364]\tvalid_0's auc: 0.968907\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 5357.5 Total: 7797.125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 72390, number of negative: 527610\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1042\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 51\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (6.87 MB) transferred to GPU in 0.004824 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120650 -> initscore=-1.986289\n",
      "[LightGBM] [Info] Start training from score -1.986289\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1304]\tvalid_0's auc: 0.968825\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 5239.1875 Total: 7797.125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 72390, number of negative: 527610\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1039\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 51\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (6.87 MB) transferred to GPU in 0.007140 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120650 -> initscore=-1.986289\n",
      "[LightGBM] [Info] Start training from score -1.986289\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1348]\tvalid_0's auc: 0.96992\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 5346.4375 Total: 7797.125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Number of positive: 72390, number of negative: 527610\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1043\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 51\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (6.87 MB) transferred to GPU in 0.004995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120650 -> initscore=-1.986289\n",
      "[LightGBM] [Info] Start training from score -1.986289\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1361]\tvalid_0's auc: 0.969442\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/tunahan/anaconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=250, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=250\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 5485.0625 Total: 7797.125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    }
   ],
   "source": [
    "lgb_test_preds = []\n",
    "cat_test_preds = []\n",
    "ffnn_test_preds = []\n",
    "\n",
    "for fold,(tr_idx,va_idx) in enumerate(kf.split(X, y)):\n",
    "    print(\"Fold\", fold+1)\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "    # -------- FFNN --------\n",
    "    X_tr_nn = prep_nn.fit_transform(X_tr)\n",
    "    X_va_nn = prep_nn.transform(X_va)\n",
    "    XTEST_NN = prep_nn.transform(XTEST)\n",
    "\n",
    "    oof_ffnn[va_idx], ffnn_model = train_ffnn_oof(X_tr_nn, y_tr, X_va_nn)\n",
    "    with torch.no_grad():\n",
    "        Xt = torch.tensor(np.asarray(XTEST_NN), dtype=torch.float32).to(device)\n",
    "        ffnn_test_preds.append(ffnn_model(Xt).cpu().squeeze().numpy())\n",
    "\n",
    "    # -------- LightGBM --------\n",
    "    Xtr_tree = prep_tree.fit_transform(X_tr)\n",
    "    Xva_tree = prep_tree.transform(X_va)\n",
    "    XTEST_TREE = prep_tree.transform(XTEST)\n",
    "\n",
    "    m1 = lgb.LGBMClassifier(\n",
    "        objective=\"binary\", metric=\"auc\",\n",
    "        boosting_type=\"gbdt\", device=\"gpu\",\n",
    "        n_estimators=20000, learning_rate=0.03,\n",
    "        num_leaves=128, min_data_in_leaf=250,\n",
    "        feature_fraction=0.8, bagging_fraction=0.8,\n",
    "        bagging_freq=1, lambda_l2=3.0, random_state=42\n",
    "    )\n",
    "    m1.fit(Xtr_tree, y_tr,\n",
    "           eval_set=[(Xva_tree, y_va)],\n",
    "           eval_metric=\"auc\",\n",
    "           callbacks=[lgb.early_stopping(200), lgb.log_evaluation(0)])\n",
    "    oof_lgb[va_idx] = np.asarray(m1.predict_proba(Xva_tree))[:, 1]\n",
    "    lgb_test_preds.append(np.asarray(m1.predict_proba(XTEST_TREE))[:, 1])\n",
    "\n",
    "    # -------- CatBoost --------\n",
    "    prep_cat = SimpleImputer(strategy=\"median\").fit(X_tr[num_cols])\n",
    "    Xtr_cb = X_tr.copy();   Xtr_cb[num_cols] = prep_cat.transform(X_tr[num_cols])\n",
    "    Xva_cb = X_va.copy();   Xva_cb[num_cols] = prep_cat.transform(X_va[num_cols])\n",
    "    XTEST_CAT = XTEST.copy(); XTEST_CAT[num_cols] = prep_cat.transform(XTEST[num_cols])\n",
    "\n",
    "    for c in cat_cols:\n",
    "        Xtr_cb[c]    = Xtr_cb[c].astype(\"category\")\n",
    "        Xva_cb[c]    = Xva_cb[c].astype(\"category\")\n",
    "        XTEST_CAT[c] = XTEST_CAT[c].astype(\"category\")\n",
    "\n",
    "    cat_idx = [Xtr_cb.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    m2 = CatBoostClassifier(\n",
    "        task_type=\"GPU\", devices=\"0\",\n",
    "        loss_function=\"Logloss\", eval_metric=\"AUC\",\n",
    "        iterations=10000, learning_rate=0.03, depth=8,\n",
    "        l2_leaf_reg=3.0, bagging_temperature=1.0,\n",
    "        random_strength=0.2, border_count=128,\n",
    "        early_stopping_rounds=300, verbose=False, random_state=42\n",
    "    )\n",
    "    m2.fit(Xtr_cb, y_tr, eval_set=(Xva_cb, y_va),\n",
    "           use_best_model=True, cat_features=cat_idx)\n",
    "\n",
    "    oof_cat[va_idx] = np.asarray(m2.predict_proba(Xva_cb))[:, 1]\n",
    "    cat_test_preds.append(np.asarray(m2.predict_proba(XTEST_CAT))[:, 1])\n",
    "    \n",
    "# -------- fold ortalamasÄ± --------\n",
    "ffnn_test_pred = np.mean(ffnn_test_preds, axis=0)\n",
    "lgb_test_pred  = np.mean(lgb_test_preds,  axis=0)\n",
    "cat_test_pred  = np.mean(cat_test_preds,  axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e2bd391",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta = X.reset_index(drop=True).copy()\n",
    "X_meta[\"pred_ffnn\"] = oof_ffnn\n",
    "X_meta[\"pred_lgb\"]  = oof_lgb\n",
    "X_meta[\"pred_cat\"]  = oof_cat\n",
    "y_meta = y.reset_index(drop=True)\n",
    "\n",
    "pred_cols = [\"pred_ffnn\",\"pred_lgb\",\"pred_cat\"]\n",
    "meta_prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "        (\"pred\", \"passthrough\", pred_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28da7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta_tr, xtemp, y_meta_tr, ytemp = train_test_split(X_meta, \n",
    "                                                              y_meta, \n",
    "                                                              test_size=0.15, \n",
    "                                                              stratify=y_meta, \n",
    "                                                              random_state=42)\n",
    "\n",
    "X_meta_test, X_meta_va, y_meta_test, y_meta_va = train_test_split(xtemp, \n",
    "                                                              ytemp, \n",
    "                                                              test_size=0.33, \n",
    "                                                              stratify=ytemp, \n",
    "                                                              random_state=42)\n",
    "X_meta_tr = meta_prep.fit_transform(X_meta_tr)\n",
    "X_meta_va = meta_prep.transform(X_meta_va)\n",
    "X_meta_test = meta_prep.transform(X_meta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6011b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(X_any, y_ser, batch=768, shuffle=True):\n",
    "    Xnp = np.asarray(X_any, dtype=np.float32)\n",
    "    ynp = np.asarray(y_ser, dtype=np.float32).reshape(-1, 1)\n",
    "    return DataLoader(\n",
    "        TensorDataset(torch.tensor(Xnp), torch.tensor(ynp)),\n",
    "        batch_size=batch, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "train_loader = make_loader(X_meta_tr, y_meta_tr, shuffle=True)\n",
    "val_loader   = make_loader(X_meta_va, y_meta_va, shuffle=False)\n",
    "test_loader   = make_loader(X_meta_test, y_meta_test, shuffle=False)\n",
    "\n",
    "meta_model = FFNN(X_meta_tr.shape[1]).to(device)\n",
    "meta_crit  = FocalLoss()\n",
    "meta_opt   = optim.AdamW(meta_model.parameters(), lr=1e-3)\n",
    "meta_sch   = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                 meta_opt, T_0=10, T_mult=2, eta_min=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b794c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val AUC = 0.9664\n",
      "Epoch 2: Val AUC = 0.9663\n",
      "Epoch 3: Val AUC = 0.9667\n",
      "Epoch 4: Val AUC = 0.9668\n",
      "Epoch 5: Val AUC = 0.9670\n",
      "Epoch 6: Val AUC = 0.9671\n",
      "Epoch 7: Val AUC = 0.9672\n",
      "Epoch 8: Val AUC = 0.9674\n",
      "Epoch 9: Val AUC = 0.9674\n",
      "Epoch 10: Val AUC = 0.9674\n",
      "Epoch 11: Val AUC = 0.9671\n",
      "Epoch 12: Val AUC = 0.9671\n",
      "Epoch 13: Val AUC = 0.9673\n",
      "Epoch 14: Val AUC = 0.9672\n",
      "Epoch 15: Val AUC = 0.9672\n",
      "Epoch 16: Val AUC = 0.9672\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "best_auc, cnt = 0, 0\n",
    "for epoch in range(50):\n",
    "    meta_model.train()\n",
    "    for xb,yb in train_loader:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        meta_opt.zero_grad()\n",
    "        loss = meta_crit(meta_model(xb), yb)\n",
    "        loss.backward(); meta_opt.step()\n",
    "    meta_model.eval()\n",
    "    allp,ally = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in val_loader:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            p = meta_model(xb).cpu().squeeze().numpy()\n",
    "            allp.append(p); ally.append(yb.cpu().squeeze().numpy())\n",
    "    val_auc = roc_auc_score(np.concatenate(ally), np.concatenate(allp))\n",
    "    print(f\"Epoch {epoch+1}: Val AUC = {val_auc:.4f}\")\n",
    "    meta_sch.step(epoch+1)\n",
    "    if val_auc > best_auc + 1e-4:\n",
    "        best_auc = val_auc; cnt=0\n",
    "        torch.save(meta_model.state_dict(),\"best_meta.pt\")\n",
    "    else:\n",
    "        cnt+=1\n",
    "        if cnt>=8:\n",
    "            print(\"Early stopping\"); break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf83d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model.load_state_dict(torch.load(\"best_meta.pt\"))\n",
    "meta_model.eval()\n",
    "\n",
    "def pred(model, dataloader, batch=2048):\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataloader:\n",
    "            xb = xb.to(device)\n",
    "            out = model(xb).cpu().squeeze().numpy()\n",
    "            preds.append(out)\n",
    "            labels.append(yb.cpu().squeeze().numpy())\n",
    "    return np.concatenate(preds), np.concatenate(labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bac958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout AUC: 0.9687924708215341\n"
     ]
    }
   ],
   "source": [
    "preds, labels = pred(meta_model, test_loader)\n",
    "print(\"Holdout AUC:\", roc_auc_score(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "720df7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test = XTEST.reset_index(drop=True).copy()\n",
    "X_final_test[\"pred_ffnn\"] = ffnn_test_pred\n",
    "X_final_test[\"pred_lgb\"]  = lgb_test_pred\n",
    "X_final_test[\"pred_cat\"]  = cat_test_pred\n",
    "X_final_test = meta_prep.transform(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fca1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    Xt = torch.tensor(X_final_test, dtype=torch.float32).to(device)\n",
    "    preds = meta_model(Xt).cpu().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf625660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv yazÄ±ldÄ±.\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"id\": test_df[\"id\"], \"y\": preds})\n",
    "submission.to_csv(\"submission.csv\", index=False, float_format=\"%.9f\")\n",
    "print(\"submission.csv yazÄ±ldÄ±.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
